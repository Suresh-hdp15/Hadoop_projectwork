Hadoop Commands:
****************
cat	=>  Copies source paths to stdout	
  I/P -> hadoop fs -cat Tempdir/input.txt
  O/P -> This is demonstarte how to place the file from local to HDFS.
       I am learning how to setup single process and running all nodes.

copyFromLocal  => Similar to -put command, except that the source is restricted to a local file reference
I/P -> hadoop fs -copyFromLocal Samplefile.txt /user/suresh/Tempdir/input.txt

copyToLocal  => Similar to -get command, except that the destination is restricted to a local file reference
I/P -> hadoop fs -copyToLocal /user/suresh/Tempdir/sample1.txt newcopy.txt

count => Count the number of directories, files and bytes under the paths that match the specified file pattern. Get the quota and the usage. The output columns with -count are: DIR_COUNT, FILE_COUNT, CONTENT_SIZE, PATHNAME
I/P ->   hadoop fs -count -q /user/suresh/Tempdir
O/P ->  100              97            none       inf        1            2  152 hdfs://192.168.177.130:9000/user/suresh/Tempdir

cp  =>   Copy files from source to destination
I/P ->   "hadoop fs -cp /user/suresh/Tempdir/input.txt /user/suresh/hdp_user/nwipt.txt

du =>  Displays sizes of files and directories contained in the given directory or the length of a file in case its just a file
I/P -> "hadoop dfs -du /user/suresh
O/P -> Found 2 items
127         hdfs://192.168.177.130:9000/user/suresh/Tempdir
4           hdfs://192.168.177.130:9000/user/suresh/home
"

dus  => Displays summary of file length
I/P ->  "hadoop fs -dus /user/suresh/hdp_user
O/P ->  hdfs://192.168.177.130:9000/user/suresh/hdp_user 8248544

mkdir => It creates a directory
"suresh@ubuntu:~$ hadoop fs -mkdir TempDir
suresh@ubuntu:~$ hadoop fs -ls
Found 1 items
drwxr-xr-x   - suresh supergroup          0 2017-11-17 06:38 /user/suresh/TempDir
"

ls => list the directories and files in hdfs
"suresh@ubuntu:~$ hadoop fs -ls
Found 2 items
drwxr-xr-x   - suresh supergroup          0 2017-11-17 06:38 /user/suresh/TempDir
-rw-r--r--   1 suresh supergroup        127 2017-11-17 06:52 /user/suresh/hdfsinput.txt
suresh@ubuntu:~$ 
"

lsr => list the directories and files in hdfs by recursively
"hadoop fs -lsr /user/suresh/hdp_user
-rw-r--r--   1 suresh supergroup    7285588 2017-11-19 02:06 /user/suresh/hdp_user/mitesh.mp4
-rw-r--r--   1 suresh supergroup        127 2017-11-19 02:39 /user/suresh/hdp_user/nwipt.txt
-rw-r--r--   1 suresh supergroup     962829 2017-11-19 01:44 /user/suresh/hdp_user/suresh1.jpg
"

chmod => Change the permissions of files. With -R, make the change recursively through the directory structure. The user must be the owner of the file, or else a super-user.
"hadoop fs -chmod -R 777 /user/suresh/hdp_user
drwxrwxrwx   - suresh supergroup          0 2017-11-19 02:39 /user/suresh/hdp_user
"

rm => Deletes the file in HDFS 
"hadoop fs -rm /user/suresh/Tempdir/function.3gp
Deleted hdfs://192.168.177.130:9000/user/suresh/Tempdir/function.3gp
"
















